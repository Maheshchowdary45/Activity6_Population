{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshchowdary45/Activity6_Population/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" I love to eat pizza on weekends.\n",
        "She goes to the gym every morning.\n",
        "The sun is shining brightly today.\n",
        "We are learning natural language processing.\n",
        "He forgot to bring his notebook.\n",
        "My favorite color is blue.\n",
        "The children are playing in the park.\n",
        "I need to buy some groceries today.\n",
        "They are planning a trip to Europe.\n",
        "The movie was really interesting and fun.\n",
        "Artificial intelligence is transforming the world.\n",
        "I trained a machine learning model on this dataset.\n",
        "Neural networks are inspired by the human brain.\n",
        "The LSTM model is good for sequential data.\n",
        "Natural language processing is a branch of AI.\n",
        "What is your favorite food?\n",
        "Where are you going tomorrow?\n",
        "How does this algorithm work?\n",
        "Can you help me with this project?\n",
        "Why is deep learning so powerful?\"\"\""
      ],
      "metadata": {
        "id": "rLKyMbX1fPYO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "6339pAN_fURs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiating tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "uU4hvkaYfWh-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abxDPNHgfYxI",
        "outputId": "b34e8b0a-05de-4fbb-cbe4-ab2568875ec5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88rBX617faux",
        "outputId": "9328a88e-0434-4a6b-a9e9-48503008d6c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "760"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split(\"\\n\"):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY5qoCRtfdHR",
        "outputId": "e35b7aac-84bd-4bd0-a044-dad5d04360c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I love to eat pizza on weekends.\n",
            "She goes to the gym every morning.\n",
            "The sun is shining brightly today.\n",
            "We are learning natural language processing.\n",
            "He forgot to bring his notebook.\n",
            "My favorite color is blue.\n",
            "The children are playing in the park.\n",
            "I need to buy some groceries today.\n",
            "They are planning a trip to Europe.\n",
            "The movie was really interesting and fun.\n",
            "Artificial intelligence is transforming the world.\n",
            "I trained a machine learning model on this dataset.\n",
            "Neural networks are inspired by the human brain.\n",
            "The LSTM model is good for sequential data.\n",
            "Natural language processing is a branch of AI.\n",
            "What is your favorite food?\n",
            "Where are you going tomorrow?\n",
            "How does this algorithm work?\n",
            "Can you help me with this project?\n",
            "Why is deep learning so powerful?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split(\"\\n\"):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDh8fthOffN5",
        "outputId": "46c7c94c-861a-42d3-f91a-f6cb4fa5303f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 17, 3, 18, 19, 9, 20]\n",
            "[21, 22, 3, 1, 23, 24, 25]\n",
            "[1, 26, 2, 27, 28, 10]\n",
            "[29, 4, 6, 11, 12, 13]\n",
            "[30, 31, 3, 32, 33, 34]\n",
            "[35, 14, 36, 2, 37]\n",
            "[1, 38, 4, 39, 40, 1, 41]\n",
            "[5, 42, 3, 43, 44, 45, 10]\n",
            "[46, 4, 47, 7, 48, 3, 49]\n",
            "[1, 50, 51, 52, 53, 54, 55]\n",
            "[56, 57, 2, 58, 1, 59]\n",
            "[5, 60, 7, 61, 6, 15, 9, 8, 62]\n",
            "[63, 64, 4, 65, 66, 1, 67, 68]\n",
            "[1, 69, 15, 2, 70, 71, 72, 73]\n",
            "[11, 12, 13, 2, 7, 74, 75, 76]\n",
            "[77, 2, 78, 14, 79]\n",
            "[80, 4, 16, 81, 82]\n",
            "[83, 84, 8, 85, 86]\n",
            "[87, 16, 88, 89, 90, 8, 91]\n",
            "[92, 2, 93, 6, 94, 95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "\n",
        "for sentence in text.split(\"\\n\"):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequence.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "JZFyLALdfh1E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Crja8sdfj9W",
        "outputId": "73ebc959-e9b7-4f34-e67a-0f77930c6abd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 17],\n",
              " [5, 17, 3],\n",
              " [5, 17, 3, 18],\n",
              " [5, 17, 3, 18, 19],\n",
              " [5, 17, 3, 18, 19, 9],\n",
              " [5, 17, 3, 18, 19, 9, 20],\n",
              " [21, 22],\n",
              " [21, 22, 3],\n",
              " [21, 22, 3, 1],\n",
              " [21, 22, 3, 1, 23],\n",
              " [21, 22, 3, 1, 23, 24],\n",
              " [21, 22, 3, 1, 23, 24, 25],\n",
              " [1, 26],\n",
              " [1, 26, 2],\n",
              " [1, 26, 2, 27],\n",
              " [1, 26, 2, 27, 28],\n",
              " [1, 26, 2, 27, 28, 10],\n",
              " [29, 4],\n",
              " [29, 4, 6],\n",
              " [29, 4, 6, 11],\n",
              " [29, 4, 6, 11, 12],\n",
              " [29, 4, 6, 11, 12, 13],\n",
              " [30, 31],\n",
              " [30, 31, 3],\n",
              " [30, 31, 3, 32],\n",
              " [30, 31, 3, 32, 33],\n",
              " [30, 31, 3, 32, 33, 34],\n",
              " [35, 14],\n",
              " [35, 14, 36],\n",
              " [35, 14, 36, 2],\n",
              " [35, 14, 36, 2, 37],\n",
              " [1, 38],\n",
              " [1, 38, 4],\n",
              " [1, 38, 4, 39],\n",
              " [1, 38, 4, 39, 40],\n",
              " [1, 38, 4, 39, 40, 1],\n",
              " [1, 38, 4, 39, 40, 1, 41],\n",
              " [5, 42],\n",
              " [5, 42, 3],\n",
              " [5, 42, 3, 43],\n",
              " [5, 42, 3, 43, 44],\n",
              " [5, 42, 3, 43, 44, 45],\n",
              " [5, 42, 3, 43, 44, 45, 10],\n",
              " [46, 4],\n",
              " [46, 4, 47],\n",
              " [46, 4, 47, 7],\n",
              " [46, 4, 47, 7, 48],\n",
              " [46, 4, 47, 7, 48, 3],\n",
              " [46, 4, 47, 7, 48, 3, 49],\n",
              " [1, 50],\n",
              " [1, 50, 51],\n",
              " [1, 50, 51, 52],\n",
              " [1, 50, 51, 52, 53],\n",
              " [1, 50, 51, 52, 53, 54],\n",
              " [1, 50, 51, 52, 53, 54, 55],\n",
              " [56, 57],\n",
              " [56, 57, 2],\n",
              " [56, 57, 2, 58],\n",
              " [56, 57, 2, 58, 1],\n",
              " [56, 57, 2, 58, 1, 59],\n",
              " [5, 60],\n",
              " [5, 60, 7],\n",
              " [5, 60, 7, 61],\n",
              " [5, 60, 7, 61, 6],\n",
              " [5, 60, 7, 61, 6, 15],\n",
              " [5, 60, 7, 61, 6, 15, 9],\n",
              " [5, 60, 7, 61, 6, 15, 9, 8],\n",
              " [5, 60, 7, 61, 6, 15, 9, 8, 62],\n",
              " [63, 64],\n",
              " [63, 64, 4],\n",
              " [63, 64, 4, 65],\n",
              " [63, 64, 4, 65, 66],\n",
              " [63, 64, 4, 65, 66, 1],\n",
              " [63, 64, 4, 65, 66, 1, 67],\n",
              " [63, 64, 4, 65, 66, 1, 67, 68],\n",
              " [1, 69],\n",
              " [1, 69, 15],\n",
              " [1, 69, 15, 2],\n",
              " [1, 69, 15, 2, 70],\n",
              " [1, 69, 15, 2, 70, 71],\n",
              " [1, 69, 15, 2, 70, 71, 72],\n",
              " [1, 69, 15, 2, 70, 71, 72, 73],\n",
              " [11, 12],\n",
              " [11, 12, 13],\n",
              " [11, 12, 13, 2],\n",
              " [11, 12, 13, 2, 7],\n",
              " [11, 12, 13, 2, 7, 74],\n",
              " [11, 12, 13, 2, 7, 74, 75],\n",
              " [11, 12, 13, 2, 7, 74, 75, 76],\n",
              " [77, 2],\n",
              " [77, 2, 78],\n",
              " [77, 2, 78, 14],\n",
              " [77, 2, 78, 14, 79],\n",
              " [80, 4],\n",
              " [80, 4, 16],\n",
              " [80, 4, 16, 81],\n",
              " [80, 4, 16, 81, 82],\n",
              " [83, 84],\n",
              " [83, 84, 8],\n",
              " [83, 84, 8, 85],\n",
              " [83, 84, 8, 85, 86],\n",
              " [87, 16],\n",
              " [87, 16, 88],\n",
              " [87, 16, 88, 89],\n",
              " [87, 16, 88, 89, 90],\n",
              " [87, 16, 88, 89, 90, 8],\n",
              " [87, 16, 88, 89, 90, 8, 91],\n",
              " [92, 2],\n",
              " [92, 2, 93],\n",
              " [92, 2, 93, 6],\n",
              " [92, 2, 93, 6, 94],\n",
              " [92, 2, 93, 6, 94, 95]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence ])"
      ],
      "metadata": {
        "id": "rOG4Hh9Qfmgm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "dP3lkGwkfpnj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequence,maxlen = max_len,padding=\"pre\")"
      ],
      "metadata": {
        "id": "U290vQa0fszf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHhr242efvBI",
        "outputId": "8e38c6cd-e491-4ee8-9f4f-d7605162bd3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  5, 17],\n",
              "       [ 0,  0,  0, ...,  5, 17,  3],\n",
              "       [ 0,  0,  0, ..., 17,  3, 18],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  2, 93,  6],\n",
              "       [ 0,  0,  0, ..., 93,  6, 94],\n",
              "       [ 0,  0,  0, ...,  6, 94, 95]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "BbFnfoDkfxFV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAlCY3J3fzxi",
        "outputId": "d6dbb6fe-61e9-4989-e54b-b26d25270dd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'to': 3,\n",
              " 'are': 4,\n",
              " 'i': 5,\n",
              " 'learning': 6,\n",
              " 'a': 7,\n",
              " 'this': 8,\n",
              " 'on': 9,\n",
              " 'today': 10,\n",
              " 'natural': 11,\n",
              " 'language': 12,\n",
              " 'processing': 13,\n",
              " 'favorite': 14,\n",
              " 'model': 15,\n",
              " 'you': 16,\n",
              " 'love': 17,\n",
              " 'eat': 18,\n",
              " 'pizza': 19,\n",
              " 'weekends': 20,\n",
              " 'she': 21,\n",
              " 'goes': 22,\n",
              " 'gym': 23,\n",
              " 'every': 24,\n",
              " 'morning': 25,\n",
              " 'sun': 26,\n",
              " 'shining': 27,\n",
              " 'brightly': 28,\n",
              " 'we': 29,\n",
              " 'he': 30,\n",
              " 'forgot': 31,\n",
              " 'bring': 32,\n",
              " 'his': 33,\n",
              " 'notebook': 34,\n",
              " 'my': 35,\n",
              " 'color': 36,\n",
              " 'blue': 37,\n",
              " 'children': 38,\n",
              " 'playing': 39,\n",
              " 'in': 40,\n",
              " 'park': 41,\n",
              " 'need': 42,\n",
              " 'buy': 43,\n",
              " 'some': 44,\n",
              " 'groceries': 45,\n",
              " 'they': 46,\n",
              " 'planning': 47,\n",
              " 'trip': 48,\n",
              " 'europe': 49,\n",
              " 'movie': 50,\n",
              " 'was': 51,\n",
              " 'really': 52,\n",
              " 'interesting': 53,\n",
              " 'and': 54,\n",
              " 'fun': 55,\n",
              " 'artificial': 56,\n",
              " 'intelligence': 57,\n",
              " 'transforming': 58,\n",
              " 'world': 59,\n",
              " 'trained': 60,\n",
              " 'machine': 61,\n",
              " 'dataset': 62,\n",
              " 'neural': 63,\n",
              " 'networks': 64,\n",
              " 'inspired': 65,\n",
              " 'by': 66,\n",
              " 'human': 67,\n",
              " 'brain': 68,\n",
              " 'lstm': 69,\n",
              " 'good': 70,\n",
              " 'for': 71,\n",
              " 'sequential': 72,\n",
              " 'data': 73,\n",
              " 'branch': 74,\n",
              " 'of': 75,\n",
              " 'ai': 76,\n",
              " 'what': 77,\n",
              " 'your': 78,\n",
              " 'food': 79,\n",
              " 'where': 80,\n",
              " 'going': 81,\n",
              " 'tomorrow': 82,\n",
              " 'how': 83,\n",
              " 'does': 84,\n",
              " 'algorithm': 85,\n",
              " 'work': 86,\n",
              " 'can': 87,\n",
              " 'help': 88,\n",
              " 'me': 89,\n",
              " 'with': 90,\n",
              " 'project': 91,\n",
              " 'why': 92,\n",
              " 'deep': 93,\n",
              " 'so': 94,\n",
              " 'powerful': 95}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes = 96)"
      ],
      "metadata": {
        "id": "gLUFHlemf3G6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiYFE-lf5tr",
        "outputId": "edbfe073-25be-4453-8ded-0115c9bf2e9d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBb8f_if7sU",
        "outputId": "26bfc3db-429f-4c63-b427-37d8d5811649"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense"
      ],
      "metadata": {
        "id": "9nWXh-Smf9vz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 96\n",
        "\n",
        "# Initialize the Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=96, output_dim=100, input_length=8))\n",
        "\n",
        "# Add the LSTM layer\n",
        "model.add(GRU(150))\n",
        "\n",
        "# Add the Dense output layer\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwU-v3HwgAlE",
        "outputId": "720440dc-2dfc-4311-ee6f-b357d9e44852"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 8))"
      ],
      "metadata": {
        "id": "8T8UM3iqjAdw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pYofsgiAgDLP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "QNOUelIkgLIM",
        "outputId": "c5b5298e-95e9-40c2-899a-76f87da704d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │         \u001b[38;5;34m9,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m113,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m14,496\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,496</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,496\u001b[0m (537.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,496</span> (537.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,496\u001b[0m (537.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,496</span> (537.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D30wwKH9gRdL",
        "outputId": "859f28f6-9263-4da1-8e23-4fa42b0535d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.0113 - loss: 4.5672\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0790 - loss: 4.5450\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1060 - loss: 4.5237\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1216 - loss: 4.4973\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0966 - loss: 4.4558\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0924 - loss: 4.3898\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0510 - loss: 4.2714\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0531 - loss: 4.2333\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0521 - loss: 4.0210\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1070 - loss: 4.0712\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1409 - loss: 4.0415\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1528 - loss: 3.9856\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0991 - loss: 3.9492\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1362 - loss: 3.8274\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1708 - loss: 3.7500\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1833 - loss: 3.6079\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2433 - loss: 3.5315\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2640 - loss: 3.4502 \n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2682 - loss: 3.3341\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2467 - loss: 3.2745\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2313 - loss: 3.1738\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2857 - loss: 2.9866\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3187 - loss: 2.9119 \n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3149 - loss: 2.8326\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3580 - loss: 2.7739\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4344 - loss: 2.5965\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4857 - loss: 2.4312 \n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4829 - loss: 2.3149\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5159 - loss: 2.1660\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5568 - loss: 2.0429\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6173 - loss: 1.8883\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6229 - loss: 1.7291\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6524 - loss: 1.6131\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6711 - loss: 1.5182\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7382 - loss: 1.3586\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7914 - loss: 1.2426\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8168 - loss: 1.1681\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8426 - loss: 1.0678\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8644 - loss: 0.9965\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8774 - loss: 0.9303\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9339 - loss: 0.8396\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9205 - loss: 0.7592\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8903 - loss: 0.7569\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9287 - loss: 0.6990\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9079 - loss: 0.6391\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9256 - loss: 0.5980\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.5279\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9100 - loss: 0.5106\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8954 - loss: 0.5389\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9365 - loss: 0.4566\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9260 - loss: 0.4608\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9204 - loss: 0.4228\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9484 - loss: 0.3986\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9499 - loss: 0.3642\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9510 - loss: 0.3305\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9588 - loss: 0.3242\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9525 - loss: 0.3341\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9613 - loss: 0.2910\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9530 - loss: 0.3008\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9499 - loss: 0.2819\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9504 - loss: 0.2742\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9561 - loss: 0.2673\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9499 - loss: 0.2505\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9499 - loss: 0.2450\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9436 - loss: 0.2395\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9519 - loss: 0.2205\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9436 - loss: 0.2278\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9363 - loss: 0.2591\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9551 - loss: 0.2004\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9342 - loss: 0.2421\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9551 - loss: 0.2026\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9499 - loss: 0.1932\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9603 - loss: 0.1866\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9499 - loss: 0.1918\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9484 - loss: 0.1830\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9484 - loss: 0.1607\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9707 - loss: 0.1461\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9551 - loss: 0.1550\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9561 - loss: 0.1468\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9613 - loss: 0.1605\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9467 - loss: 0.1728\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9665 - loss: 0.1326\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9348 - loss: 0.1699\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9436 - loss: 0.1613\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9436 - loss: 0.1645\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9696 - loss: 0.1304\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9582 - loss: 0.1410\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9484 - loss: 0.1447 \n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9686 - loss: 0.1274\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9582 - loss: 0.1363\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9613 - loss: 0.1311\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9390 - loss: 0.1497\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9582 - loss: 0.1235\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9551 - loss: 0.1403\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9613 - loss: 0.1138\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9161 - loss: 0.1658\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9499 - loss: 0.1393\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9519 - loss: 0.1355\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9515 - loss: 0.1240\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9759 - loss: 0.1024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f902d195950>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "\n",
        "text_2 = \"They are planning a\""
      ],
      "metadata": {
        "id": "JNd2Q4eE7QBE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenixatioin\n",
        "tokenized_text_2 = tokenizer.texts_to_sequences([text_2])[0]\n",
        "tokenized_text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMFDwort7QXV",
        "outputId": "f0ba102b-3b1b-46e8-f340-886b2ae3f1d5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46, 4, 47, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding\n",
        "padding_text_2 = pad_sequences([tokenized_text_2],maxlen = 8,padding=\"pre\")\n",
        "padding_text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-qmrTE_8J7X",
        "outputId": "4ecf0f5a-76c7-4737-b6b1-28d56425ce2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0, 46,  4, 47,  7]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "predicted_probs = model.predict(padding_text_2)\n",
        "predicted_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJLUxraO8ev4",
        "outputId": "270fe0f8-5f99-40b0-bc40-aa717bb3932d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.44115745e-06, 7.21784425e-04, 1.04503043e-03, 3.35024064e-03,\n",
              "        5.14271142e-06, 1.06973289e-06, 2.60861753e-03, 3.08628165e-04,\n",
              "        1.19908203e-04, 1.17395008e-04, 5.41067834e-07, 6.40600570e-04,\n",
              "        9.62923223e-04, 7.22976620e-05, 2.71110417e-04, 8.18988265e-05,\n",
              "        3.49082911e-05, 8.59596403e-05, 3.36145131e-05, 7.71087143e-05,\n",
              "        1.49631171e-06, 1.58717637e-06, 2.85322658e-05, 1.03075208e-05,\n",
              "        1.57421368e-06, 1.24192297e-06, 1.28628917e-05, 5.86844590e-06,\n",
              "        4.63815704e-05, 2.65966582e-06, 1.71646263e-06, 3.74828058e-04,\n",
              "        7.33209963e-05, 1.27381383e-04, 1.21856601e-05, 1.98992598e-06,\n",
              "        2.80870227e-05, 3.27931616e-06, 3.86307238e-06, 1.07701471e-05,\n",
              "        5.01769828e-05, 4.66223755e-05, 3.88002518e-05, 1.81579584e-04,\n",
              "        1.88854669e-04, 6.30137174e-06, 4.01067211e-07, 5.14981548e-05,\n",
              "        9.64996755e-01, 1.08067696e-04, 8.67999279e-06, 1.13513643e-05,\n",
              "        1.56766746e-05, 1.00091211e-05, 7.47456988e-06, 8.19790671e-07,\n",
              "        1.61397509e-06, 2.07030807e-05, 1.41622833e-04, 3.17202989e-06,\n",
              "        1.39696567e-04, 1.46294888e-02, 5.49255674e-07, 5.15954116e-06,\n",
              "        6.11607029e-05, 2.79175118e-04, 1.03122751e-04, 2.33645801e-06,\n",
              "        1.74674412e-07, 2.61486298e-06, 2.99667026e-05, 3.95903362e-06,\n",
              "        4.53197117e-07, 2.27842051e-07, 3.53000150e-03, 1.94069929e-04,\n",
              "        3.82508551e-06, 3.58938610e-06, 1.38890555e-05, 4.71548992e-05,\n",
              "        9.90283297e-07, 9.20104445e-04, 1.71296985e-03, 6.21558138e-06,\n",
              "        4.97174187e-05, 2.74041842e-04, 9.23293046e-05, 3.13273449e-06,\n",
              "        1.05166197e-04, 2.97743478e-04, 7.72144558e-05, 6.95764311e-06,\n",
              "        2.98509985e-06, 1.83331256e-04, 3.18303173e-05, 4.19462140e-06]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predicted_index = np.argmax(model.predict(padding_text_2))\n",
        "predicted_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIEmIkZs8xSQ",
        "outputId": "4d17e0cb-518c-41e7-8502-921827412a92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(48)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_word = ''\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_index:\n",
        "        predicted_word = word\n",
        "        break\n",
        "\n",
        "print(\"Next word prediction:\", predicted_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtCFlynu9NTj",
        "outputId": "e91385b2-aa79-4ea3-8b1a-e0985424d283"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: trip\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxzn+z0r3N+vxavdLFVrzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maheshchowdary45/Activity6_Population/blob/main/LSTM1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" I love to eat pizza on weekends.\n",
        "She goes to the gym every morning.\n",
        "The sun is shining brightly today.\n",
        "We are learning natural language processing.\n",
        "He forgot to bring his notebook.\n",
        "My favorite color is blue.\n",
        "The children are playing in the park.\n",
        "I need to buy some groceries today.\n",
        "They are planning a trip to Europe.\n",
        "The movie was really interesting and fun.\n",
        "Artificial intelligence is transforming the world.\n",
        "I trained a machine learning model on this dataset.\n",
        "Neural networks are inspired by the human brain.\n",
        "The LSTM model is good for sequential data.\n",
        "Natural language processing is a branch of AI.\n",
        "What is your favorite food?\n",
        "Where are you going tomorrow?\n",
        "How does this algorithm work?\n",
        "Can you help me with this project?\n",
        "Why is deep learning so powerful?\"\"\""
      ],
      "metadata": {
        "id": "rLKyMbX1fPYO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "6339pAN_fURs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiating tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "uU4hvkaYfWh-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abxDPNHgfYxI",
        "outputId": "c6777506-69b1-4c8c-99b2-8235405287c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88rBX617faux",
        "outputId": "8e04b4e9-3f38-4824-ba18-d77e6e122cbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "760"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split(\"\\n\"):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY5qoCRtfdHR",
        "outputId": "37a3d388-744b-45c8-9938-6a7e1044839b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I love to eat pizza on weekends.\n",
            "She goes to the gym every morning.\n",
            "The sun is shining brightly today.\n",
            "We are learning natural language processing.\n",
            "He forgot to bring his notebook.\n",
            "My favorite color is blue.\n",
            "The children are playing in the park.\n",
            "I need to buy some groceries today.\n",
            "They are planning a trip to Europe.\n",
            "The movie was really interesting and fun.\n",
            "Artificial intelligence is transforming the world.\n",
            "I trained a machine learning model on this dataset.\n",
            "Neural networks are inspired by the human brain.\n",
            "The LSTM model is good for sequential data.\n",
            "Natural language processing is a branch of AI.\n",
            "What is your favorite food?\n",
            "Where are you going tomorrow?\n",
            "How does this algorithm work?\n",
            "Can you help me with this project?\n",
            "Why is deep learning so powerful?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split(\"\\n\"):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDh8fthOffN5",
        "outputId": "5158a7de-68dd-4d3b-98b5-4d2426406129"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 17, 3, 18, 19, 9, 20]\n",
            "[21, 22, 3, 1, 23, 24, 25]\n",
            "[1, 26, 2, 27, 28, 10]\n",
            "[29, 4, 6, 11, 12, 13]\n",
            "[30, 31, 3, 32, 33, 34]\n",
            "[35, 14, 36, 2, 37]\n",
            "[1, 38, 4, 39, 40, 1, 41]\n",
            "[5, 42, 3, 43, 44, 45, 10]\n",
            "[46, 4, 47, 7, 48, 3, 49]\n",
            "[1, 50, 51, 52, 53, 54, 55]\n",
            "[56, 57, 2, 58, 1, 59]\n",
            "[5, 60, 7, 61, 6, 15, 9, 8, 62]\n",
            "[63, 64, 4, 65, 66, 1, 67, 68]\n",
            "[1, 69, 15, 2, 70, 71, 72, 73]\n",
            "[11, 12, 13, 2, 7, 74, 75, 76]\n",
            "[77, 2, 78, 14, 79]\n",
            "[80, 4, 16, 81, 82]\n",
            "[83, 84, 8, 85, 86]\n",
            "[87, 16, 88, 89, 90, 8, 91]\n",
            "[92, 2, 93, 6, 94, 95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "\n",
        "for sentence in text.split(\"\\n\"):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequence.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "JZFyLALdfh1E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Crja8sdfj9W",
        "outputId": "d46f9cd9-c008-4a0b-d5b1-e1c7b05f09eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 17],\n",
              " [5, 17, 3],\n",
              " [5, 17, 3, 18],\n",
              " [5, 17, 3, 18, 19],\n",
              " [5, 17, 3, 18, 19, 9],\n",
              " [5, 17, 3, 18, 19, 9, 20],\n",
              " [21, 22],\n",
              " [21, 22, 3],\n",
              " [21, 22, 3, 1],\n",
              " [21, 22, 3, 1, 23],\n",
              " [21, 22, 3, 1, 23, 24],\n",
              " [21, 22, 3, 1, 23, 24, 25],\n",
              " [1, 26],\n",
              " [1, 26, 2],\n",
              " [1, 26, 2, 27],\n",
              " [1, 26, 2, 27, 28],\n",
              " [1, 26, 2, 27, 28, 10],\n",
              " [29, 4],\n",
              " [29, 4, 6],\n",
              " [29, 4, 6, 11],\n",
              " [29, 4, 6, 11, 12],\n",
              " [29, 4, 6, 11, 12, 13],\n",
              " [30, 31],\n",
              " [30, 31, 3],\n",
              " [30, 31, 3, 32],\n",
              " [30, 31, 3, 32, 33],\n",
              " [30, 31, 3, 32, 33, 34],\n",
              " [35, 14],\n",
              " [35, 14, 36],\n",
              " [35, 14, 36, 2],\n",
              " [35, 14, 36, 2, 37],\n",
              " [1, 38],\n",
              " [1, 38, 4],\n",
              " [1, 38, 4, 39],\n",
              " [1, 38, 4, 39, 40],\n",
              " [1, 38, 4, 39, 40, 1],\n",
              " [1, 38, 4, 39, 40, 1, 41],\n",
              " [5, 42],\n",
              " [5, 42, 3],\n",
              " [5, 42, 3, 43],\n",
              " [5, 42, 3, 43, 44],\n",
              " [5, 42, 3, 43, 44, 45],\n",
              " [5, 42, 3, 43, 44, 45, 10],\n",
              " [46, 4],\n",
              " [46, 4, 47],\n",
              " [46, 4, 47, 7],\n",
              " [46, 4, 47, 7, 48],\n",
              " [46, 4, 47, 7, 48, 3],\n",
              " [46, 4, 47, 7, 48, 3, 49],\n",
              " [1, 50],\n",
              " [1, 50, 51],\n",
              " [1, 50, 51, 52],\n",
              " [1, 50, 51, 52, 53],\n",
              " [1, 50, 51, 52, 53, 54],\n",
              " [1, 50, 51, 52, 53, 54, 55],\n",
              " [56, 57],\n",
              " [56, 57, 2],\n",
              " [56, 57, 2, 58],\n",
              " [56, 57, 2, 58, 1],\n",
              " [56, 57, 2, 58, 1, 59],\n",
              " [5, 60],\n",
              " [5, 60, 7],\n",
              " [5, 60, 7, 61],\n",
              " [5, 60, 7, 61, 6],\n",
              " [5, 60, 7, 61, 6, 15],\n",
              " [5, 60, 7, 61, 6, 15, 9],\n",
              " [5, 60, 7, 61, 6, 15, 9, 8],\n",
              " [5, 60, 7, 61, 6, 15, 9, 8, 62],\n",
              " [63, 64],\n",
              " [63, 64, 4],\n",
              " [63, 64, 4, 65],\n",
              " [63, 64, 4, 65, 66],\n",
              " [63, 64, 4, 65, 66, 1],\n",
              " [63, 64, 4, 65, 66, 1, 67],\n",
              " [63, 64, 4, 65, 66, 1, 67, 68],\n",
              " [1, 69],\n",
              " [1, 69, 15],\n",
              " [1, 69, 15, 2],\n",
              " [1, 69, 15, 2, 70],\n",
              " [1, 69, 15, 2, 70, 71],\n",
              " [1, 69, 15, 2, 70, 71, 72],\n",
              " [1, 69, 15, 2, 70, 71, 72, 73],\n",
              " [11, 12],\n",
              " [11, 12, 13],\n",
              " [11, 12, 13, 2],\n",
              " [11, 12, 13, 2, 7],\n",
              " [11, 12, 13, 2, 7, 74],\n",
              " [11, 12, 13, 2, 7, 74, 75],\n",
              " [11, 12, 13, 2, 7, 74, 75, 76],\n",
              " [77, 2],\n",
              " [77, 2, 78],\n",
              " [77, 2, 78, 14],\n",
              " [77, 2, 78, 14, 79],\n",
              " [80, 4],\n",
              " [80, 4, 16],\n",
              " [80, 4, 16, 81],\n",
              " [80, 4, 16, 81, 82],\n",
              " [83, 84],\n",
              " [83, 84, 8],\n",
              " [83, 84, 8, 85],\n",
              " [83, 84, 8, 85, 86],\n",
              " [87, 16],\n",
              " [87, 16, 88],\n",
              " [87, 16, 88, 89],\n",
              " [87, 16, 88, 89, 90],\n",
              " [87, 16, 88, 89, 90, 8],\n",
              " [87, 16, 88, 89, 90, 8, 91],\n",
              " [92, 2],\n",
              " [92, 2, 93],\n",
              " [92, 2, 93, 6],\n",
              " [92, 2, 93, 6, 94],\n",
              " [92, 2, 93, 6, 94, 95]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence ])"
      ],
      "metadata": {
        "id": "rOG4Hh9Qfmgm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "dP3lkGwkfpnj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequence,maxlen = max_len,padding=\"pre\")"
      ],
      "metadata": {
        "id": "U290vQa0fszf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHhr242efvBI",
        "outputId": "952401c2-a56e-453a-9c53-949f23ebd7dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  5, 17],\n",
              "       [ 0,  0,  0, ...,  5, 17,  3],\n",
              "       [ 0,  0,  0, ..., 17,  3, 18],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  2, 93,  6],\n",
              "       [ 0,  0,  0, ..., 93,  6, 94],\n",
              "       [ 0,  0,  0, ...,  6, 94, 95]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "BbFnfoDkfxFV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAlCY3J3fzxi",
        "outputId": "2ff334d7-181e-487f-acff-2a0fb30a1851"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'to': 3,\n",
              " 'are': 4,\n",
              " 'i': 5,\n",
              " 'learning': 6,\n",
              " 'a': 7,\n",
              " 'this': 8,\n",
              " 'on': 9,\n",
              " 'today': 10,\n",
              " 'natural': 11,\n",
              " 'language': 12,\n",
              " 'processing': 13,\n",
              " 'favorite': 14,\n",
              " 'model': 15,\n",
              " 'you': 16,\n",
              " 'love': 17,\n",
              " 'eat': 18,\n",
              " 'pizza': 19,\n",
              " 'weekends': 20,\n",
              " 'she': 21,\n",
              " 'goes': 22,\n",
              " 'gym': 23,\n",
              " 'every': 24,\n",
              " 'morning': 25,\n",
              " 'sun': 26,\n",
              " 'shining': 27,\n",
              " 'brightly': 28,\n",
              " 'we': 29,\n",
              " 'he': 30,\n",
              " 'forgot': 31,\n",
              " 'bring': 32,\n",
              " 'his': 33,\n",
              " 'notebook': 34,\n",
              " 'my': 35,\n",
              " 'color': 36,\n",
              " 'blue': 37,\n",
              " 'children': 38,\n",
              " 'playing': 39,\n",
              " 'in': 40,\n",
              " 'park': 41,\n",
              " 'need': 42,\n",
              " 'buy': 43,\n",
              " 'some': 44,\n",
              " 'groceries': 45,\n",
              " 'they': 46,\n",
              " 'planning': 47,\n",
              " 'trip': 48,\n",
              " 'europe': 49,\n",
              " 'movie': 50,\n",
              " 'was': 51,\n",
              " 'really': 52,\n",
              " 'interesting': 53,\n",
              " 'and': 54,\n",
              " 'fun': 55,\n",
              " 'artificial': 56,\n",
              " 'intelligence': 57,\n",
              " 'transforming': 58,\n",
              " 'world': 59,\n",
              " 'trained': 60,\n",
              " 'machine': 61,\n",
              " 'dataset': 62,\n",
              " 'neural': 63,\n",
              " 'networks': 64,\n",
              " 'inspired': 65,\n",
              " 'by': 66,\n",
              " 'human': 67,\n",
              " 'brain': 68,\n",
              " 'lstm': 69,\n",
              " 'good': 70,\n",
              " 'for': 71,\n",
              " 'sequential': 72,\n",
              " 'data': 73,\n",
              " 'branch': 74,\n",
              " 'of': 75,\n",
              " 'ai': 76,\n",
              " 'what': 77,\n",
              " 'your': 78,\n",
              " 'food': 79,\n",
              " 'where': 80,\n",
              " 'going': 81,\n",
              " 'tomorrow': 82,\n",
              " 'how': 83,\n",
              " 'does': 84,\n",
              " 'algorithm': 85,\n",
              " 'work': 86,\n",
              " 'can': 87,\n",
              " 'help': 88,\n",
              " 'me': 89,\n",
              " 'with': 90,\n",
              " 'project': 91,\n",
              " 'why': 92,\n",
              " 'deep': 93,\n",
              " 'so': 94,\n",
              " 'powerful': 95}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes = 96)"
      ],
      "metadata": {
        "id": "gLUFHlemf3G6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiYFE-lf5tr",
        "outputId": "14c910c5-9a3b-4571-8591-ac4d31b9c651"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBb8f_if7sU",
        "outputId": "27dd8ed4-f8bb-4a7c-ae96-396cfc17f376"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "9nWXh-Smf9vz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 96\n",
        "\n",
        "# Initialize the Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=96, output_dim=100, input_length=8))\n",
        "\n",
        "# Add the LSTM layer\n",
        "model.add(LSTM(150))\n",
        "\n",
        "# Add the Dense output layer\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwU-v3HwgAlE",
        "outputId": "1dfd7871-8c21-4786-da46-b19a0d4dd142"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 8))"
      ],
      "metadata": {
        "id": "8T8UM3iqjAdw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pYofsgiAgDLP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "QNOUelIkgLIM",
        "outputId": "0fd0fdad-12a8-4603-f654-aa6590c7afdc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │         \u001b[38;5;34m9,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m14,496\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,496</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,696\u001b[0m (682.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,696</span> (682.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m174,696\u001b[0m (682.41 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,696</span> (682.41 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D30wwKH9gRdL",
        "outputId": "79bd62a2-a6e7-48b1-b5af-c357c985a3cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0149 - loss: 4.5630\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0656 - loss: 4.5440\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0573 - loss: 4.5146\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0552 - loss: 4.4623\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0583 - loss: 4.3390\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0552 - loss: 4.2488\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0510 - loss: 4.2307\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0734 - loss: 4.1898\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0859 - loss: 4.1254\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0510 - loss: 4.1443\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0781 - loss: 4.0997\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0656 - loss: 4.0776\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0763 - loss: 3.9912\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1339 - loss: 3.9587\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1432 - loss: 3.8727\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1446 - loss: 3.8589\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1329 - loss: 3.7500\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1287 - loss: 3.6923\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1722 - loss: 3.5772\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1435 - loss: 3.5936\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1893 - loss: 3.4549\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1539 - loss: 3.3320\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2124 - loss: 3.2585\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2060 - loss: 3.2193\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2400 - loss: 3.0565\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3515 - loss: 2.9312\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3271 - loss: 2.9161\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3674 - loss: 2.7909\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4482 - loss: 2.5996\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4179 - loss: 2.5532\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4696 - loss: 2.4365\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4802 - loss: 2.3288\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5150 - loss: 2.2002\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5905 - loss: 2.1148\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6074 - loss: 2.0126\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6546 - loss: 1.9123\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6609 - loss: 1.8614\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6156 - loss: 1.8523\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6618 - loss: 1.7702\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6589 - loss: 1.7267\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7046 - loss: 1.5862\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6926 - loss: 1.6075\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6842 - loss: 1.5314\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7524 - loss: 1.3917\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7435 - loss: 1.3374\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7923 - loss: 1.2507\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7926 - loss: 1.2557\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7743 - loss: 1.2338\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8247 - loss: 1.1140\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7763 - loss: 1.1150\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7738 - loss: 1.1126\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8199 - loss: 1.0371 \n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7815 - loss: 1.0432\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7699 - loss: 1.0495\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8244 - loss: 0.9865\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8353 - loss: 0.9564\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8284 - loss: 0.9733\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8565 - loss: 0.8619\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8591 - loss: 0.8192\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8876 - loss: 0.7529\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8890 - loss: 0.8146\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8829 - loss: 0.7369\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8339 - loss: 0.7886\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8641 - loss: 0.7631\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8729 - loss: 0.7125\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8759 - loss: 0.7459\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9000 - loss: 0.6386\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8765 - loss: 0.6453\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9134 - loss: 0.6116\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9076 - loss: 0.6026\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9326 - loss: 0.5624\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9132 - loss: 0.6136\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9287 - loss: 0.5850\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9330 - loss: 0.5037\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9001 - loss: 0.5943\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9339 - loss: 0.5032\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9443 - loss: 0.4799\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9442 - loss: 0.4743\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9604 - loss: 0.4697\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9287 - loss: 0.4625\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9379 - loss: 0.4706\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 0.4525\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9432 - loss: 0.4329\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9452 - loss: 0.4295\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9463 - loss: 0.4283\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9400 - loss: 0.3775\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9504 - loss: 0.3735\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9609 - loss: 0.3659\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9692 - loss: 0.3332\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9426 - loss: 0.3924\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9655 - loss: 0.3342\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9405 - loss: 0.3907\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9624 - loss: 0.3328\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9467 - loss: 0.3449\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.2897\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9530 - loss: 0.3045\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9519 - loss: 0.3189\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9488 - loss: 0.3012\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9374 - loss: 0.3240\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9655 - loss: 0.2669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4a68524d90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "\n",
        "text_2 = \"My favorite is\""
      ],
      "metadata": {
        "id": "JNd2Q4eE7QBE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenixatioin\n",
        "tokenized_text_2 = tokenizer.texts_to_sequences([text_2])[0]\n",
        "tokenized_text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMFDwort7QXV",
        "outputId": "5662206c-cb50-49a7-a3bd-3ee6f3517f2c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[35, 14, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding\n",
        "padding_text_2 = pad_sequences([tokenized_text_2],maxlen = 8,padding=\"pre\")\n",
        "padding_text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-qmrTE_8J7X",
        "outputId": "10afcfeb-2454-42d4-e879-7d7e249a5ce7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0, 35, 14,  2]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "predicted_probs = model.predict(padding_text_2)\n",
        "predicted_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJLUxraO8ev4",
        "outputId": "0cd966ef-6f3c-47ee-88e5-073a90532da0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.02384016e-04, 1.75294606e-03, 2.70799715e-02, 2.71021319e-03,\n",
              "        3.45322042e-04, 6.17627447e-05, 7.48264464e-03, 3.62574449e-03,\n",
              "        5.15951123e-03, 7.94137741e-05, 9.06340574e-05, 1.06752901e-04,\n",
              "        2.90152908e-04, 4.14545764e-04, 1.04480803e-01, 1.16659177e-03,\n",
              "        5.02673793e-04, 7.29156367e-04, 1.41691987e-03, 4.74802451e-04,\n",
              "        2.45208957e-05, 4.14965616e-05, 1.46838173e-03, 1.91170286e-04,\n",
              "        4.42544952e-05, 8.38057349e-06, 2.70636356e-03, 2.20244918e-02,\n",
              "        2.77177338e-03, 5.40760047e-05, 5.76189705e-05, 3.60149704e-03,\n",
              "        1.59427524e-02, 7.65712990e-04, 3.82730941e-04, 7.79536731e-06,\n",
              "        7.64659122e-02, 3.21092695e-01, 1.75024988e-03, 4.20533150e-04,\n",
              "        2.05499397e-04, 9.98688938e-06, 7.12226785e-04, 7.14914128e-03,\n",
              "        5.32753766e-04, 1.54111840e-04, 3.58560210e-05, 3.86798434e-04,\n",
              "        4.75928333e-04, 1.65526944e-05, 2.15338217e-03, 1.00012394e-02,\n",
              "        4.91031492e-03, 1.37667300e-03, 5.06670876e-05, 1.56267051e-05,\n",
              "        2.49314744e-05, 1.98178599e-03, 6.23090938e-02, 1.22903060e-04,\n",
              "        7.26263155e-04, 6.21985295e-04, 1.03692828e-05, 2.43406557e-05,\n",
              "        7.12887631e-05, 1.96337394e-04, 6.78423603e-05, 1.84706550e-05,\n",
              "        2.70140595e-06, 2.24442245e-03, 3.90414568e-03, 4.60156356e-04,\n",
              "        9.94961465e-06, 1.19863580e-05, 8.95463687e-04, 3.41401319e-04,\n",
              "        1.57850845e-05, 2.60683282e-05, 2.20126972e-01, 1.61030479e-02,\n",
              "        2.82201490e-05, 4.53769026e-04, 7.04360573e-05, 1.60269065e-05,\n",
              "        2.47064536e-03, 9.57519282e-03, 1.84431451e-03, 3.59232072e-05,\n",
              "        6.42212294e-03, 2.77144299e-03, 1.55762373e-03, 8.35373430e-05,\n",
              "        2.78571370e-05, 2.59659793e-02, 1.89874624e-03, 3.78360011e-04]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predicted_index = np.argmax(model.predict(padding_text_2))\n",
        "predicted_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIEmIkZs8xSQ",
        "outputId": "8b880ee5-e94c-4af2-8ab2-aade3bd37899"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(37)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_word = ''\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_index:\n",
        "        predicted_word = word\n",
        "        break\n",
        "\n",
        "print(\"Next word prediction:\", predicted_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtCFlynu9NTj",
        "outputId": "92378d75-ccb6-4eb5-be02-28cc304242cd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: blue\n"
          ]
        }
      ]
    }
  ]
}